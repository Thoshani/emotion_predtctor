{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOjxAPZc929CpvaOtubu0Fm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# Cell 1: Install & Import Libraries\n",
        "# ========================================\n",
        "\n",
        "!pip install -q gradio\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "from collections import Counter\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import gradio as gr\n",
        "import datetime\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaOR0LHAc8-Z",
        "outputId": "fa3547df-4e5a-4933-b721-a8ba7daedcb5"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "#  Load & Combine CSVs\n",
        "# ================================\n",
        "\n",
        "# Upload your files in Colab manually or mount Google Drive\n",
        "\n",
        "# Example: load files (adjust filenames if needed)\n",
        "df_train = pd.read_csv(\"/content/train.txt\", sep=';', names=['text', 'emotion'])\n",
        "df_val = pd.read_csv(\"/content/val.txt\", sep=';', names=['text', 'emotion'])\n",
        "df_test = pd.read_csv(\"/content/test.txt\", sep=';', names=['text', 'emotion'])\n",
        "\n",
        "print(\"Train shape:\", df_train.shape)\n",
        "print(\"Validation shape:\", df_val.shape)\n",
        "print(\"Test shape:\", df_test.shape)\n",
        "\n",
        "print(\"Sample rows:\")\n",
        "print(df_train.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvkus0JcdUIX",
        "outputId": "3cd0b372-4498-4d4a-ccf7-e11603b84f79"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (16000, 2)\n",
            "Validation shape: (2000, 2)\n",
            "Test shape: (2000, 2)\n",
            "Sample rows:\n",
            "                                                text  emotion\n",
            "0                            i didnt feel humiliated  sadness\n",
            "1  i can go from feeling so hopeless to so damned...  sadness\n",
            "2   im grabbing a minute to post i feel greedy wrong    anger\n",
            "3  i am ever feeling nostalgic about the fireplac...     love\n",
            "4                               i am feeling grouchy    anger\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# Combine, check unique emotions, find & remove common words\n",
        "# ========================================\n",
        "\n",
        "# Combine\n",
        "df_all = pd.concat([df_train, df_val, df_test], ignore_index=True)\n",
        "print(\"Combined shape:\", df_all.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3qng_SWgb5j",
        "outputId": "61adcfda-56d1-47fd-88f3-c4322f9abd5e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined shape: (20000, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check missing values\n",
        "df_all.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "lZmliHG9hII1",
        "outputId": "38d71c08-2bff-4d03-a526-2ee9ffdbe046"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text       0\n",
              "emotion    0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>text</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show unique emotions\n",
        "unique_emotions = df_all['emotion'].unique()\n",
        "print(\"Unique emotion labels:\", unique_emotions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AYT9DzVgffe",
        "outputId": "a362b9d0-3036-491a-ec15-5aad1ffebb30"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique emotion labels: ['sadness' 'anger' 'love' 'surprise' 'fear' 'joy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_all['emotion'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "liO-IW5lhrlF",
        "outputId": "fbdedc52-79c5-477d-ca5c-e42951ef8a6a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "emotion\n",
              "joy         6761\n",
              "sadness     5797\n",
              "anger       2709\n",
              "fear        2373\n",
              "love        1641\n",
              "surprise     719\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>joy</th>\n",
              "      <td>6761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sadness</th>\n",
              "      <td>5797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>anger</th>\n",
              "      <td>2709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fear</th>\n",
              "      <td>2373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>love</th>\n",
              "      <td>1641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>surprise</th>\n",
              "      <td>719</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load normal stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Quick token frequency count to see top words\n",
        "from collections import Counter\n",
        "\n",
        "all_words = []\n",
        "for text in df_all['text']:\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    all_words.extend(text.split())\n",
        "\n",
        "word_freq = Counter(all_words)\n",
        "print(\"Most common words:\")\n",
        "print(word_freq.most_common(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFq0twkYiBjY",
        "outputId": "37e9d668-25e8-4a97-bce9-154ad9c4fdba"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most common words:\n",
            "[('i', 32242), ('feel', 13938), ('and', 11996), ('to', 11208), ('the', 10462), ('a', 7748), ('feeling', 6431), ('that', 6314), ('of', 6182), ('my', 5326), ('in', 4239), ('it', 3922), ('like', 3616), ('so', 3127), ('im', 3055), ('for', 3021), ('me', 2899), ('was', 2828), ('have', 2803), ('but', 2790)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NLTK stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "#  custom stopwords to catch leftover generic words\n",
        "custom_stopwords = {\n",
        "    'feel', 'feeling', 'really', 'very', 'just', 'always',\n",
        "    'today', 'now', 'im', 'ive', 'ill', 'cant', 'dont',\n",
        "    'get', 'got', 'much', 'lot',\n",
        "    'one', 'thing', 'know', 'like', 'people', 'time'\n",
        "}\n",
        "\n",
        "all_stopwords = stop_words.union(custom_stopwords)\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    text = text.strip()\n",
        "    words = text.split()\n",
        "    words = [w for w in words if w not in all_stopwords]\n",
        "    return ' '.join(words)\n",
        "\n",
        "df_all['clean_text'] = df_all['text'].apply(clean_text)\n",
        "\n",
        "print(\"\\nSample cleaned rows:\")\n",
        "print(df_all[['text', 'clean_text', 'emotion']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zC7CjABKgSuy",
        "outputId": "b359894d-cdbc-4225-f8b5-9c498424b208"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample cleaned rows:\n",
            "                                                text  \\\n",
            "0                            i didnt feel humiliated   \n",
            "1  i can go from feeling so hopeless to so damned...   \n",
            "2   im grabbing a minute to post i feel greedy wrong   \n",
            "3  i am ever feeling nostalgic about the fireplac...   \n",
            "4                               i am feeling grouchy   \n",
            "\n",
            "                                          clean_text  emotion  \n",
            "0                                   didnt humiliated  sadness  \n",
            "1  go hopeless damned hopeful around someone care...  sadness  \n",
            "2                  grabbing minute post greedy wrong    anger  \n",
            "3            ever nostalgic fireplace still property     love  \n",
            "4                                            grouchy    anger  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# split\n",
        "# ========================================\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Input and target\n",
        "X = df_all['clean_text'].values\n",
        "y = df_all['emotion'].values\n",
        "\n",
        "# First split: 70% Train, 30% Temp\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.30, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Second split: Temp → Validation and Test (50% each → 15% each overall)\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "print(\"Training samples:\", len(X_train))\n",
        "print(\"Validation samples:\", len(X_val))\n",
        "print(\"Test samples:\", len(X_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUATjyADiWGT",
        "outputId": "87eb58ec-fb1c-41c8-8650-9bac28a79de7"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 14000\n",
            "Validation samples: 3000\n",
            "Test samples: 3000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# Cell 5: TF-IDF Vectorization\n",
        "# ========================================\n",
        "\n",
        "# Create TF-IDF vectorizer with a good limit on features\n",
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "\n",
        "# Fit only on training text\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_val_tfidf = tfidf.transform(X_val)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "print(\"TF-IDF vectorization complete.\")\n",
        "print(\"Train TF-IDF shape:\", X_train_tfidf.shape)\n",
        "print(\"Validation TF-IDF shape:\", X_val_tfidf.shape)\n",
        "print(\"Test TF-IDF shape:\", X_test_tfidf.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9Ja6izkkiCR",
        "outputId": "e287270c-8425-4594-bcb5-f74e15c96849"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF vectorization complete.\n",
            "Train TF-IDF shape: (14000, 5000)\n",
            "Validation TF-IDF shape: (3000, 5000)\n",
            "Test TF-IDF shape: (3000, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# Cell 6: Train Logistic Regression\n",
        "# ========================================\n",
        "\n",
        "\n",
        "# Initialize model\n",
        "lr_model = LogisticRegression(max_iter=200)\n",
        "\n",
        "# Train model\n",
        "lr_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print(\"Logistic Regression training complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJs1nSGBknre",
        "outputId": "0eb50339-c7b1-4cee-b356-5e34b1523768"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# Cell 7: Evaluate Logistic Regression (with metrics)\n",
        "# ========================================\n",
        "\n",
        "# Predict on test data\n",
        "y_pred_lr = lr_model.predict(X_test_tfidf)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred_lr)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Detailed report: precision, recall, F1 for each class and averages\n",
        "report = classification_report(y_test, y_pred_lr, digits=4)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(report)\n",
        "\n",
        "# Get average precision, recall, F1 (macro)\n",
        "precision = precision_score(y_test, y_pred_lr, average='macro')\n",
        "recall = recall_score(y_test, y_pred_lr, average='macro')\n",
        "f1 = f1_score(y_test, y_pred_lr, average='macro')\n",
        "\n",
        "print(f\"\\nMacro Average Precision: {precision:.4f}\")\n",
        "print(f\"Macro Average Recall:    {recall:.4f}\")\n",
        "print(f\"Macro Average F1 Score:  {f1:.4f}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred_lr)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxB4U_hrku5N",
        "outputId": "1d606bee-2606-4615-c05c-4ed31370057f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8760\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger     0.9145    0.7887    0.8470       407\n",
            "        fear     0.8903    0.7978    0.8415       356\n",
            "         joy     0.8440    0.9655    0.9006      1014\n",
            "        love     0.8883    0.6789    0.7696       246\n",
            "     sadness     0.8949    0.9402    0.9169       869\n",
            "    surprise     0.8696    0.5556    0.6780       108\n",
            "\n",
            "    accuracy                         0.8760      3000\n",
            "   macro avg     0.8836    0.7878    0.8256      3000\n",
            "weighted avg     0.8783    0.8760    0.8723      3000\n",
            "\n",
            "\n",
            "Macro Average Precision: 0.8836\n",
            "Macro Average Recall:    0.7878\n",
            "Macro Average F1 Score:  0.8256\n",
            "\n",
            "Confusion Matrix:\n",
            "[[321   9  38   0  39   0]\n",
            " [  9 284  25   2  30   6]\n",
            " [  3   4 979  15  12   1]\n",
            " [  3   1  66 167   8   1]\n",
            " [ 12   4  31   4 817   1]\n",
            " [  3  17  21   0   7  60]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# Gradio Chatbot for Logistic Regression\n",
        "# ========================================\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "def predict_emotion_lr(text):\n",
        "    # Clean text same as training\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    text = text.strip()\n",
        "    words = text.split()\n",
        "    words = [w for w in words if w not in all_stopwords]\n",
        "    cleaned = ' '.join(words)\n",
        "\n",
        "    # Transform with TF-IDF\n",
        "    vector = tfidf.transform([cleaned])\n",
        "\n",
        "    # Predict with Logistic Regression\n",
        "    pred = lr_model.predict(vector)\n",
        "\n",
        "    return f\"Predicted Emotion: {pred[0]}\"\n",
        "\n",
        "# Build Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=predict_emotion_lr,\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Type your text here...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"Emotion Predictor Chatbot (Logistic Regression)\",\n",
        "    description=\"Enter any text and this chatbot will predict the emotion category using Logistic Regression.\"\n",
        ")\n",
        "\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "VSn2XVrwnxS6",
        "outputId": "8df56568-ddc0-45e7-a907-2a6cb96fda4a"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://f7548f1b3c1c34b97e.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f7548f1b3c1c34b97e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set maximum number of words & max sequence length\n",
        "MAX_NUM_WORDS = 10000\n",
        "MAX_SEQUENCE_LENGTH = 100\n",
        "\n",
        "# Create and fit the tokenizer on training data only\n",
        "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# Convert text to sequences\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# Pad sequences to the same length\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
        "X_val_pad = pad_sequences(X_val_seq, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
        "\n",
        "print(\"Tokenizer and padding complete.\")\n",
        "print(\"Example sequence:\", X_train_seq[0])\n",
        "print(\"Padded shape:\", X_train_pad.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lth3wRwClWJI",
        "outputId": "adfff1a9-929d-498d-c7f9-2f7525b1d892"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer and padding complete.\n",
            "Example sequence: [45, 13, 1002]\n",
            "Padded shape: (14000, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# Cell 9: Encode Emotion Labels\n",
        "# ========================================\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Encode labels to integers\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(y_train)\n",
        "\n",
        "y_train_enc = label_encoder.transform(y_train)\n",
        "y_val_enc = label_encoder.transform(y_val)\n",
        "y_test_enc = label_encoder.transform(y_test)\n",
        "\n",
        "# Convert to categorical for Keras\n",
        "y_train_cat = to_categorical(y_train_enc)\n",
        "y_val_cat = to_categorical(y_val_enc)\n",
        "y_test_cat = to_categorical(y_test_enc)\n",
        "\n",
        "print(\"Label encoding complete. Classes:\")\n",
        "print(label_encoder.classes_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_7hNMszkueM",
        "outputId": "bbe2940c-fc13-4548-858b-b97fa1850010"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label encoding complete. Classes:\n",
            "['anger' 'fear' 'joy' 'love' 'sadness' 'surprise']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN MODEL"
      ],
      "metadata": {
        "id": "OIe8hhqLmq0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# Cell 10: Load GloVe Embeddings\n",
        "# ========================================\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Download GloVe 100D if not present\n",
        "!wget -q http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip\n",
        "\n",
        "# Load 100D GloVe\n",
        "embedding_index = {}\n",
        "with open('glove.6B.100d.txt', encoding='utf8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], dtype='float32')\n",
        "        embedding_index[word] = vector\n",
        "\n",
        "print(f\"Loaded {len(embedding_index)} word vectors from GloVe.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTYxddnUkuOl",
        "outputId": "d5a3975a-ea39-4444-b2c7-81124e9b656f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 400000 word vectors from GloVe.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# Cell 11: Create Embedding Matrix\n",
        "# ========================================\n",
        "\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "num_words = min(MAX_NUM_WORDS, len(word_index) + 1)\n",
        "\n",
        "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    if i >= MAX_NUM_WORDS:\n",
        "        continue\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "print(\"Embedding matrix shape:\", embedding_matrix.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUrhw9VKmKTz",
        "outputId": "da31e56e-a777-4af4-e4b5-7ccf3f6dfe0d"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding matrix shape: (10000, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# Cell 12: Build Bi-LSTM Model\n",
        "# ========================================\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=num_words,\n",
        "                    output_dim=EMBEDDING_DIM,\n",
        "                    weights=[embedding_matrix],\n",
        "                    input_length=MAX_SEQUENCE_LENGTH,\n",
        "                    trainable=False))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=False)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "kGhcX3-WmKQR",
        "outputId": "27d67311-feed-47d9-f7c6-17d8e4cec056"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │     \u001b[38;5;34m1,000,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,000,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,000,000\u001b[0m (3.81 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,000,000</span> (3.81 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,000,000\u001b[0m (3.81 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,000,000</span> (3.81 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# Cell 13: Train Bi-LSTM\n",
        "# ========================================\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_pad, y_train_cat,\n",
        "    validation_data=(X_val_pad, y_val_cat),\n",
        "    epochs=10,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stop]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYRWUF7XmKNK",
        "outputId": "0d04641a-c5bd-405a-820c-a1bffae9ce3f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 262ms/step - accuracy: 0.4223 - loss: 1.5003 - val_accuracy: 0.6250 - val_loss: 1.0706\n",
            "Epoch 2/10\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 192ms/step - accuracy: 0.6248 - loss: 1.0307 - val_accuracy: 0.7200 - val_loss: 0.7990\n",
            "Epoch 3/10\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 188ms/step - accuracy: 0.6995 - loss: 0.8266 - val_accuracy: 0.7723 - val_loss: 0.6586\n",
            "Epoch 4/10\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 181ms/step - accuracy: 0.7527 - loss: 0.6799 - val_accuracy: 0.8020 - val_loss: 0.5759\n",
            "Epoch 5/10\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 179ms/step - accuracy: 0.7886 - loss: 0.5869 - val_accuracy: 0.8227 - val_loss: 0.4958\n",
            "Epoch 6/10\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 185ms/step - accuracy: 0.8196 - loss: 0.5184 - val_accuracy: 0.8357 - val_loss: 0.4430\n",
            "Epoch 7/10\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 188ms/step - accuracy: 0.8323 - loss: 0.4580 - val_accuracy: 0.8497 - val_loss: 0.4175\n",
            "Epoch 8/10\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 188ms/step - accuracy: 0.8543 - loss: 0.4064 - val_accuracy: 0.8593 - val_loss: 0.3915\n",
            "Epoch 9/10\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 200ms/step - accuracy: 0.8670 - loss: 0.3710 - val_accuracy: 0.8587 - val_loss: 0.3846\n",
            "Epoch 10/10\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 190ms/step - accuracy: 0.8768 - loss: 0.3377 - val_accuracy: 0.8713 - val_loss: 0.3626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# Cell 14: Evaluate Bi-LSTM\n",
        "# ========================================\n",
        "\n",
        "# Predict\n",
        "y_pred_rnn_prob = model.predict(X_test_pad)\n",
        "y_pred_rnn = np.argmax(y_pred_rnn_prob, axis=1)\n",
        "\n",
        "# True labels\n",
        "y_true_rnn = np.argmax(y_test_cat, axis=1)\n",
        "\n",
        "# Metrics\n",
        "accuracy = accuracy_score(y_true_rnn, y_pred_rnn)\n",
        "precision = precision_score(y_true_rnn, y_pred_rnn, average='macro')\n",
        "recall = recall_score(y_true_rnn, y_pred_rnn, average='macro')\n",
        "f1 = f1_score(y_true_rnn, y_pred_rnn, average='macro')\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Macro Precision: {precision:.4f}\")\n",
        "print(f\"Macro Recall: {recall:.4f}\")\n",
        "print(f\"Macro F1 Score: {f1:.4f}\")\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_true_rnn, y_pred_rnn)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPoFp__TmKKf",
        "outputId": "d9ec5bf0-c228-4eb7-daf0-a252c84febae"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step\n",
            "Accuracy: 0.8707\n",
            "Macro Precision: 0.8349\n",
            "Macro Recall: 0.8321\n",
            "Macro F1 Score: 0.8334\n",
            "\n",
            "Confusion Matrix:\n",
            "[[368   8  15   1  14   1]\n",
            " [ 11 291   6   2  26  20]\n",
            " [ 16  10 906  41  38   3]\n",
            " [  5   1  41 191   8   0]\n",
            " [ 26  21  31   8 780   3]\n",
            " [  1  22   8   0   1  76]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# Cell 15: Gradio Emotion Chatbot\n",
        "# ========================================\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "# Define a function that takes user input → cleans → predicts\n",
        "def predict_emotion(text):\n",
        "    # Clean text same as training\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    text = text.strip()\n",
        "    words = text.split()\n",
        "    words = [w for w in words if w not in all_stopwords]\n",
        "    cleaned = ' '.join(words)\n",
        "\n",
        "    # Tokenize and pad\n",
        "    seq = tokenizer.texts_to_sequences([cleaned])\n",
        "    pad = pad_sequences(seq, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
        "\n",
        "    # Predict\n",
        "    pred = model.predict(pad)\n",
        "    label = label_encoder.inverse_transform([np.argmax(pred)])\n",
        "\n",
        "    return f\"Predicted Emotion: {label[0]}\"\n",
        "\n",
        "# Build Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=predict_emotion,\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Type your text here...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"Emotion Predictor Chatbot\",\n",
        "    description=\"Enter any text and this chatbot will predict the emotion category.\"\n",
        ")\n",
        "\n",
        "# Launch\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "KxRoj8GImgd2",
        "outputId": "1cbce79b-5fd3-43d1-ef13-e7acdf64bc15"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://ba2d977ed0a44020aa.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ba2d977ed0a44020aa.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/train.txt\")\n",
        "files.download(\"/content/val.txt\")\n",
        "files.download(\"/content/test.txt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "F_UFfBj-_eEU",
        "outputId": "eb7ab2f6-7412-41fc-c64f-f57ffdeb0729"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5f19815e-ebd2-494f-8295-dd737a2292b7\", \"train.txt\", 1658616)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ee2de094-4663-4054-ad0a-ad067e52d462\", \"val.txt\", 204240)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_df0c8770-40b0-467e-b99a-2f09850d640a\", \"test.txt\", 206760)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}